Virtual Mouse Using Hand Gesture Recognition
This project implements a virtual mouse controlled by hand gestures. Using libraries such as OpenCV, MediaPipe, and Pynput, it enables users to perform mouse actions like movement, left-click, right-click, double-click, and screenshot capture based on predefined hand gestures.

Features
Real-time mouse pointer control using hand position.
Left-click, right-click, and double-click functionality using specific gestures.
Screenshot capture using a gesture-based command.
Uses MediaPipe for accurate hand tracking with 21 landmarks.
Responsive and adaptable to different screen sizes.
Technologies Used
Python: The programming language used for implementation.
OpenCV: For video capture and image processing.
MediaPipe: To track hand landmarks in real-time.
Pynput: For simulating mouse actions programmatically.
PyAutoGUI: For mapping gestures to screen dimensions and executing specific actions.
Requirements
Before running the project, ensure you have the following:

Python 3.7 or later installed.
A functional webcam or an external camera.
Required Python libraries:
opencv-python
mediapipe
pynput
pyautogui
